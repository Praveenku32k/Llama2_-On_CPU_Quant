# Llama2_-On_CPU_Quant
Llama2_ On_CPU_Quant

```
steps:

## How to Run this Project
Praveen Kumar@LAPTOP-06COBUUP MINGW64 ~/Desktop
1. First clone the repo: git clone 
git clone https://github.com/Praveenku32k/Llama2_-On_CPU_Quant.git
Cloning into 'Llama2_-On_CPU_Quant'...
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0
Receiving objects: 100% (5/5), done.

Praveen Kumar@LAPTOP-06COBUUP MINGW64 ~/Desktop
$ cd Llama2_-On_CPU_Quant/
```

```
create virtual env 
conda create -p venv python==3.10 -y
source activate venv/

```
```
model
https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main

```
llama-2-7b-chat.ggmlv3.q2_K.bin
2.87 GB

llama-2-7b-chat.ggmlv3.q3_K_L.bin
3.6 GB

llama-2-7b-chat.ggmlv3.q3_K_M.bin
3.28 GB

llama-2-7b-chat.ggmlv3.q3_K_S.bin
2.95 GB

llama-2-7b-chat.ggmlv3.q4_0.bin
3.79 GB
```
